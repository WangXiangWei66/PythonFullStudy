# 零基础机器学习到注意力机制串讲

## 1.机器学习、线性回归等

# 机器学习 VS 深度学习

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/91b5eeb750c6437d8c5662d1b30d3732.png)

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/762101ded2c44b71aff3bf703388c3ad.png)

## 机器学习类型

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/764303ca31744a1a98dcffd6070a17f6.png)

### 有监督学习

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/a57ac2c25f1a4adc88b4955f8bb5f94d.png)

## 线性回归之拟合

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/60a73a9b53c7459f9e6e1ad149d55d9b.png)

## 表达式、损失函数

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/d301902a84344bad8a16e042464c00e6.png)

## 多元线性回归

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/170a3d79b78340cc85c23a90ad6df7ca.png)

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/d9b0a815023e4979991a15908ef53395.png)

## 梯度下降

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/bfbfd1cf1acc48159648be18cbfff240.png)

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/48468b54dfb2477f8660405d98553cf8.png)

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/019992cebed04d0ebf1065089a30c016.png)

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/13db92dab41f47068a5ce3ec0ec9a0ee.png)

## 优化之升维

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/508fe7acbfe84ca498fea7ee1a7455b9.png)

## 过拟合

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/dabf932d5e944d20b98cd0e4569ec30f.png)

## early stop

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/e06a45547f8749c1b7cbb7c3b21b7887.png)

## 优化之降维

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/cbeda505e28e46f193be69ecf0c0451f.png)

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/a662178671be4fb3876362519034159c.png)

## 优化之惩罚项

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/21692ab542254b3eb91aee36058bffa3.png)

## **2. 逻辑回归、正则、归一化等**

## 正则项

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/646d50801d7349b19e092a7ae7523de9.png)

## 归一化

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/b3ebc7dc65404ae2aa1db525fbd6e3c8.png)

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/f7c493c15f674eb898da4b05a0a53e27.png)

## 逻辑回归

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/f336fc40fd034727ada43732d40c4046.png)

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/945a416c5faa411f9fa6525c1e758bcb.png)

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/4ec57f04cd2a437ebe5c9a420e217679.png)

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/68503917efec4cb2b7c63d9a56b7b958.png)

## Softmax回归

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/614aafeb89d14ec7a46c24d5ee7cd3cf.png)

## 损失函数

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/9c32af28bc18401cb62854c733521b1b.png)

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/78f3afbfb7ce40a7bec7a10a253f5582.png)

## **3. 神经网络、反向传播等**

## 神经网络

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/68b8092c81bd42b08085aa87ad9c2380.png)

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/2481877cb50a4dd984649bd036599f77.png)

## 梯度消失

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/04874b7cc86744be952ac6aa232c37b7.png)

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/735e45205e434d3093befc0078622846.png)

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/58551/1751007368079/4173480aded8471f91cfc99d64d65bea.png)

## **4. 卷积神经网络、循环神经网络**

## **5. Attention注意力机制**

# AI大模型工程师必会技能

RAG 开发（检索增强大模型）

Agent 开发（智能体）

WorkFlows 开发（工作流）

微调开发（supervised fine tuning）

大模型蒸馏和量化开发（model distillation、quantization）

MoE 从零开始训练一个大模型（Pretrain、SFT、RLHF）
